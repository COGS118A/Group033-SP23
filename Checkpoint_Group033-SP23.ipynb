{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Tyden Rucker\n",
    "- Areen Lu\n",
    "- Anya Bodhisartha\n",
    "- Nikhil Deepak\n",
    "- Jason Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Pests are one of the main issues in the agricultural industry we have today. If left unchecked, they can damage plants, food supplies, and property. According to the research, using machine learning improves the accuracy of insect detection than the traditional insect identification method.\n",
    "In this project, we are aiming to classify and detect insect pests that have greatly affected agricultural products. Additionally, we want to measure the accuracy of different machine learning methods. The data are images which are already classified and labeled. Using this data, we will be processing the data then constructing a model to create a multi-class classifier and use mean squared error or cross validation to compare different models. Utilizing different evaluation metrics such as precision and recall and cross validation, we will determine the best hyperparameters and model. Our project will focus on model selection as well as algorithm selection to determine the best model that accurately predicts the class of the insect given an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Agriculture is a substantial aspect of the world economy making up 5.4% of the United States GDP in 2021. This percentage amounts to $1.264 trillion.<a name=\"USDA\"></a>[<sup>[1]</sup>](#USDA)The performance of the agricultural sector has wide ranging ramifications and implications in all parts of everyday life. \n",
    "\n",
    "Insects are a critical component of the agricultural ecosystem. From major pollinators such as bees and mosquitoes to pests such as aphids, some insects provide vital services to farmers while others could possibly be detrimental to the survival of a crop and subsequently the livelihood of surrounding settlements. Large quantities of pests such as grasshoppers, locusts, and caterpillars can result in widespread damage to crops and potentially lead to famine.Traditionally, identifying and managing insects and pests has relied on labor intensive and time consuming methods. Farmers and other agricultural experts would visually inspect plants and use insecticides based on general knowledge of common insects. However, these approaches are limited in accuracy and efficiency, leading to environmental risks. Using machine learning for insect recognition helps solve these problems, as they process large amounts of image data. Farmers can benefit from improved accuracy and efficiency in pest management decisions. Accurate pest identification enables farmers to respond more effectively to threats, reducing the risk of crop damage and financial losses. \n",
    "\n",
    "Previous studies conducted on similar datasets, such as 9 and 24 insect classes of Wang and Xie datasets, enhanced, augmented and rescaled the images. Shape features, including area, perimeter, axis lengths, eccentricity, and compactness were then extracted from the insect images and stored in feature models. ANN, SVM, KNN, CNN (Convolutional Neural Network) and NB (Naive Bayes) algorithms were applied to classify the insects, and their performance was evaluated.<a name=\"Insect Classification\"></a>[<sup>[2]</sup>](#InsectClass) The CNN model had the highest classification accuracy of 91.5\\% and 90\\% for the Wang and Xie datasets. Another study by Xie et al. used a 19-layer CNN network which outperformed previous state-of-the-art models on the same task.<a name=\"National\"></a>[<sup>[4]</sup>](#National)\n",
    "\n",
    "It is significant to understand the optimal ways to identify insects. There are many ways to conduct insect classification, both traditional or through machine learning. However, machine learning provides an optimal solution that can be utilized to improve accuracy and efficiency of predictions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "It is difficult to identify pests with traditional methods or machine learning methods that are not suitable for image processing.\n",
    "The multilayer perceptron (MLP) or Linear Discriminant Analysis or Convolutional Neural Network are models that will be focused on for this problem. MLP is a supervised learning method that is mainly used for pattern recognition. The Linear Discriminant Analysis is another method used for data classification. A convolutional neural network may perform the best for extracting data from our data. Our dataset consists of images that are correctly classified already. Our model aims to learn from this data set through supervised machine learning in order to correctly recognize patterns within the images and label them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "UPDATED FROM PROPOSAL!\n",
    "\n",
    "\n",
    "We will be utilizing the IP102 Dataset<a name=\"IP102\"></a>[<sup>[3]</sup>](#IP102). This dataset consists of 75,222 images and 102 classes of insects. It averages 737 samples/images per class. This data set already has a split of 6:1:3.\n",
    "The insects are of varying sizes and location within the image and therefore these placements might pose as critical variables for classifying an image . The labels are represented through one hot encoding in order to create labels that have a uniform effect on the measurement of the loss. Some special handlings that will be implemented is that the images will be scaled to a fixed input size in order to minimize the space used by each image. Time augmentation will be used where images will be altered, shifted ,flipped, and color shifts/adjustments. The critical variables will be extracted from the image during training.\n",
    "\n",
    "\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.13.tar.gz (63 kB)\n",
      "     ---------------------------------------- 63.3/63.3 kB 3.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\areen\\anaconda3\\lib\\site-packages (from opendatasets) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\areen\\anaconda3\\lib\\site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\areen\\anaconda3\\lib\\site-packages (from click->opendatasets) (0.4.5)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\areen\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2022.9.14)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\areen\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\areen\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.28.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\areen\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.11)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.13-py3-none-any.whl size=77717 sha256=32ba00a18b2ac3a39702e65132375081e6c4efd2352c0f475b1a0a792d013730\n",
      "  Stored in directory: c:\\users\\areen\\appdata\\local\\pip\\cache\\wheels\\9c\\45\\15\\6d6d116cd2539fb8f450d64b0aee4a480e5366bb11b42ac763\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle, opendatasets\n",
      "Successfully installed kaggle-1.5.13 opendatasets-0.1.22\n",
      "Requirement already satisfied: pandas in c:\\users\\areen\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\areen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets \n",
    "!pip install pandas\n",
    "!pip install timm\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4) \n",
    "from tqdm import tqdm\n",
    "from textwrap import wrap\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "#import albumentations as A\n",
    "#from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import timm\n",
    "\n",
    "import opendatasets as od\n",
    "import pandas\n",
    "od.download('https://www.kaggle.com/datasets/rtlmhjbn/ip02-dataset/code?select=classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ip02-dataset/classes.txt')\n",
    "label = []\n",
    "name = []\n",
    "for line in f.readlines():\n",
    "    label.append(int(line.split()[0]))\n",
    "    name.append(' '.join(line.split()[1:]))\n",
    "classes = pd.DataFrame([label, name]).T\n",
    "classes.columns = ['label','name']\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this dataset is that due to the large sum of data and the high dimensionality of the inputs, the model is hard to make computationally efficient and iterations take a long time to run. Our preliminary base model is a Resnet34 which is a convolutional neural network that utilizes residual blocks to take in an input image of 34x34 and output a classification. All input images are resized into a 34x34 image in order to feed this into the NN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'ip02-dataset/classification'\n",
    "#stuff = os.listdir(data_path)\n",
    "#print(len(stuff))\n",
    "def resample(dataFrame,percentage,):\n",
    "    sample = int(percentage * len(dataFrame))\n",
    "    x = np.random.randint(len(dataFrame),size =sample)\n",
    "    newdf = dataFrame.drop(index = x, axis=0)\n",
    "    return newdf\n",
    "train_df = pd.read_csv('ip02-dataset/train.txt',sep=' ',header=None, engine='python')\n",
    "train_df = train_df.sample(frac=.10)\n",
    "train_df.columns = ['image_path','label']\n",
    "test_df = pd.read_csv('ip02-dataset/test.txt',sep=' ',header=None, engine='python')\n",
    "test_df = test_df.sample(frac=.10)\n",
    "test_df.columns = ['image_path','label']\n",
    "\n",
    "val_df = pd.read_csv('ip02-dataset/val.txt',sep=' ',header=None, engine='python')\n",
    "val_df = val_df.sample(frac=.10)\n",
    "val_df.columns = ['image_path','label']\n",
    "\n",
    "#print(len(train_df))\n",
    "#print(len(test_df))\n",
    "#print(len(val_df))\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "TRAIN_DIR = 'ip02-dataset/classification/train'\n",
    "TEST_DIR = 'ip02-dataset/classification/test'\n",
    "VAL_DIR = 'ip02-dataset/classification/val'\n",
    "LR = 2e-5\n",
    "BATCH_SIZE = 4\n",
    "EPOCH = 2\n",
    "print_every = 100\n",
    "dtype = torch.float32\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.RandomVerticalFlip(),\n",
    "                                     transforms.RandomAdjustSharpness(sharpness_factor=1.5),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ColorJitter(),\n",
    "                                     transforms.Resize((224,224))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is also transformed in a variety of psuedo random ways. The transforms that are applied to the input data are; a random vertical flip, a random adjustment to the sharpness, a random horizontal flip and color jitter. These flip transformations are used to increase the datasets size during training and also reduce overfitting and introduce diversity allowing the model to better generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsectDataset(Dataset):\n",
    "    def __init__(self, image, image_dir, transforms=None):\n",
    "        self.image_info = image\n",
    "        self.transforms = transforms\n",
    "        self.imgdir = image_dir\n",
    "    def __len__(self):\n",
    "        return self.image_info.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        image_info = self.image_info[index]\n",
    "        image = cv2.imread(os.path.join(self.imgdir,str(image_info[1]),image_info[0]),cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        label = image_info[1]\n",
    "        \n",
    "        image = torch.as_tensor(image, dtype=torch.float32)\n",
    "        label = torch.as_tensor(label, dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = InsectDataset(image=train_df.values, \n",
    "                              image_dir=TRAIN_DIR, \n",
    "                              transforms=data_transform)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)\n",
    "val_dataset = InsectDataset(image=val_df.values,\n",
    "                            image_dir=VAL_DIR,\n",
    "                            transforms=data_transform)\n",
    "valid_loader = DataLoader(val_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10,11,figsize=(30,30))\n",
    "images = []\n",
    "for i in classes.label:\n",
    "    random_img = random.choice(train_df[train_df.label==i-1].image_path.values)\n",
    "    label = classes.name[i-1]\n",
    "    img = plt.imread(os.path.join(TRAIN_DIR,str(i-1),random_img))\n",
    "    images.append(img)\n",
    "\n",
    "[ax.imshow(image) for image,ax in zip(images,axs.ravel())]\n",
    "[ax.set_title(\"\\n\".join(wrap(label,20))) for label,ax in zip(list(classes.name),axs.ravel())]\n",
    "[ax.set_axis_off() for ax in axs.ravel()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "\n",
    "It is essential to establish a strong connection to the problem at hand. In this case, correctly identifying insects in farming scenarios is crucial for pest control, determining optimal cultivation practices, and minimizing crop damage. By accurately classifying insects, farmers can take targeted actions and make informed decisions to optimize crop yield and reduce economic losses. \n",
    "The correct classification of insects is crucial for effective farming of crops from an economic perspective. To achieve this, we will employ an image classifier, such as a convolutional neural network (CNN) which is a multiclass classifier and by creating our own (explained below). By utilizing multiway classifiers, we take an input image and accurately classify it into predefined classes within the dataset.\n",
    "\n",
    "To construct a multiclass classifier, we will leverage different models like Linear Discriminant Analysis (LDA) and a neural network with a Multi-Layer Perceptron (MLP), aka CNN. The Sklearn library provides convenient methods for building these models and creating a classifier. It offers various options for the number of layers and solvers, allowing us to experiment and optimize the performance of the classifier. \n",
    "\n",
    "It's important to highlight the effectiveness of image classifiers in handling complex visual data. CNNs, in particular, excel at extracting features from images, enabling accurate classification, and combined with the use of LDA,  allows us to handle multiple classes and make predictions accordingly.\n",
    "\n",
    "The data set that we are currently using contains a training, test, and validation set, allowing us to perform rigorous testing and evaluation. Cross-validation techniques, such as k-fold validation, will also be applied to assess the generalization capability of the models.\n",
    "\n",
    "To establish a benchmark for testing our solution, we can utilize models that have shown high performance on similar tasks. One such model is AlexNet, which achieved impressive results on the ImageNet dataset, a large-scale image classification benchmark. By comparing the performance of our model against AlexNet, we can assess its effectiveness and determine areas for improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We will be using a confusion matrix as an evaluation metric for this project. Utilizing Precision and recall taken from the confusion matrix will allow us to create evaluation metrics. Additionally, we will use AlexNet, which is the benchmark model used for image classification.\n",
    "\n",
    "\n",
    "The formulas included in this project:\n",
    "\\begin{align*}\n",
    "Precision: \\frac{TP}{TP + FP}\\\\\n",
    "Recall: \\frac{TP}{TP + FN}\\\\\n",
    "Accuracy: \\frac{TP + TN}{TP + TN + FP + FN}\\\\\n",
    "F1: \\frac{2*Precision * Recall}{Precision + Recall}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "- Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem \n",
    "- Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "- Showing the performance of a base model/hyper-parameter setting.  Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "- Learning curves or validation curves for a particular model\n",
    "- Tables/graphs showing the performance of different models/hyper-parameters\n",
    "\n",
    "The dataset contains over 75k images and about 737 samples per a class. This is suitable to work with for solving a problem such as multi class classification, as there is a large amount of data for the model to generalize from. The problem with this dataset is that due to the large sum of data and the high dimensionality of the inputs, the model is hard to make computationally efficient and iterations take a long time to run. \n",
    "Our preliminary base model is a Resnet34 which is a convolutional neural network that utilizes residual blocks to take in an input image of 34x34 and output a classification. All input images are resized into a 34x34 image in order to feed this into the NN. The data is also transformed in a variety of psuedo random ways. The transforms that are applied to the input data are; a random vertical flip, a random adjustment to the sharpness, a random horizontal flip and color jitter. These flip transformations are used to increase the datasets size during training and also reduce overfitting and introduce diversity allowing the model to better generalize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Convolutional Neural Network (CNN) to classify multi-layer data. The dataset contains over 75k images and about 737 samples per a class. This is suitable to work with for solving a problem such as multi class classification, as there is a large amount of data for the model to generalize from. \n",
    "\n",
    "Here, we define three functions below for our image classification process: \n",
    "\n",
    "* *InsectModel* uses the vision transformer based size model to classify our insect images\n",
    "* *ThreeLayerConvNet* applies convolutions for image classification\n",
    "* *InsectDataset* loading preprocessing image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsectModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(InsectModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = timm.create_model('vit_base_patch16_224',pretrained=True,num_classes=num_classes)\n",
    "    def forward(self, image):\n",
    "        return self.model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            #f1_scores.append(f1_score(y.cpu().detach().numpy(),preds,average = 'micro'))\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        acc_list.append(acc)\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train model using epoch hyperparameter, which means that the algorithm will loop through the entire training dataset. We also use backward pass method to propagate the error whlie training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_list = []\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "labels = np.arange(102)\n",
    "f1_scores = []\n",
    "from sklearn.metrics import f1_score\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "            \n",
    "            model.train()  \n",
    "            x = x.to(device=device, dtype=dtype).float()  \n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            #f1_scores = f1_score(y.cpu().detach().numpy(),host_scores,average = 'micro',labels = labels)\n",
    "            # Zero out all the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            if t % print_every == 0:\n",
    "                loss_list.append(loss.item())\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "                check_accuracy_part34(valid_loader, model)\n",
    "                iter_list.append(t)\n",
    "                print()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = 34\n",
    "channel_2 = 68\n",
    "model = InsectModel(102)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#print(train_loader)\n",
    "train_part34(model, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_scores)\n",
    "fig,ax = plt.subplots(2)\n",
    "ax[0].set_title('Accuracy and Loss vs Iteration')\n",
    "ax[0].plot(iter_list,acc_list,label = 'Accuracy')\n",
    "ax[1].plot(iter_list,loss_list,label = 'Loss',c = 'r')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "\n",
    "acc_list = np.array(acc_list)\n",
    "#print(acc_list[acc_list.argmax()])"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our findings, we get over 55% accuracy on our testing and the results will be more accurate as we have more iterations. This shows that using CCN is an optimal solution for image classification. Moreover, we used ResNet34 a type of convolutional neural network for analyzing the sustainability of an algorithm for solving the problem. Because we have multiple layers of data from images, we have to ensure that every layers count in iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is readily available publicly on Kaggle. This eliminates the issues with data security and retention, as the data is already public. The data is sourced primarily from the Internet, relying on top 2000 search engine results for the names of insects, which could result in some collection bias. Video clips containing the insects are also used, which are captured as images at 5 frames per second. \n",
    "The images in the dataset are of insects, and do not involve human subjects or locations. This eliminates issues with consent, personally identifiable information, protected group status, or stereotype perpetuation. The output given by the algorithm may have harmful implications if insects are incorrectly identified as pests, as the overuse of pesticides can impact the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1:* Acceptable response times and commitment to the project.\n",
    "* *Team Expectation 2:* Quickly relay information if some deadlines can't be met.\n",
    "* *Team Expecation 3:* Help eachother in areas where you can.\n",
    "* *Team Expecation 4:* Be Quick and Honest about the ability to meet deadlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE THE PROPOSAL TIMELINE ACCORDING TO WHAT HAS ACTUALLY HAPPENED AND HOW IT HAS EFFECTED YOUR FUTURE PLANS\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 5/17  |  7:30 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; background research | \n",
    "| 5/20  |  12 PM |  Do theoretical research on model performance improvement techniques (Tyden) | Discuss findings and analyze evaluation metrics | \n",
    "| 5/25  | 10 AM  | Finalize Dataset Search, Start Dataset Analysis (Areen)  | Assess group members' skills to lead each specific part   |\n",
    "| 5/28  | 6 PM  |  Analyze Dataset; Begin programming for project (Tyden) | Discuss/edit project code; Complete project |\n",
    "| 6/1  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (All)| Discuss/edit full project |\n",
    "| 6/9 | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"USDA\"></a>1.[^](#USDA): United States Department of Agriculture (2 Dec 2022) What is agriculture's share of the overall U.S. economy. *United States Department of Agriculture*. https://www.ers.usda.gov/data-products/chart-gallery/gallery/chart-detail/?chartId=58270<br> \n",
    "<a name=\"Insect Classification\"></a>2.[^](#InsectClass): Thenmozhi Kasinathan, Dakshayani Singaraju, Srinivasulu Reddy Uyyala,\n",
    "Insect classification and detection in field crops using modern machine learning techniques,\n",
    "Information Processing in Agriculture,\n",
    "Volume 8, Issue 3,\n",
    "2021,\n",
    "Pages 446-457,\n",
    "ISSN 2214-3173,\n",
    "https://doi.org/10.1016/j.inpa.2020.09.006.\n",
    "(https://www.sciencedirect.com/science/article/pii/S2214317320302067)<br> \n",
    "<a name=\"IP102\"></a>3.[^](#IP102): Ratul Mahjabin (2022) IP102-Dataset https://www.kaggle.com/datasets/rtlmhjbn/ip02-dataset?select=test.txt<br>\n",
    "<a name=\"National\"></a>4.[^](#National): Xia D, Chen P, Wang B, Zhang J, Xie C. Insect Detection and Classification Based on an Improved Convolutional Neural Network. Sensors (Basel). 2018 Nov 27;18(12):4169. doi: 10.3390/s18124169. PMID: 30486481; PMCID: PMC6308804.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
